# -*- coding: utf-8 -*-
"""hacakthon_gst_file.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xQoX4ulhVJby0qXtlyqfF4DckkOdJM28
"""

# Import essential libraries for data manipulation, visualization, and machine learning
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import scipy.stats as stats
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder, StandardScaler
from google.colab import files

# Load training input features from a CSV file into a pandas DataFrame
x_train = pd.read_csv('/content/X_Train_Data_Input.csv')
# Load training target variables (labels) from a CSV file
y_train = pd.read_csv('/content/Y_Train_Data_Target.csv')
# Load test input features from a CSV file
x_test = pd.read_csv('/content/X_Test_Data_Input.csv')
# Load test target variables (labels) from a CSV file
y_test = pd.read_csv('/content/Y_Test_Data_Target.csv')

# Display the shapes of all datasets to confirm successful loading
print(y_train.shape, y_test.shape, x_train.shape, x_test.shape)

# Combine the training and test datasets to manage missing data more effectively
x_combined = pd.concat([x_train, x_test]).reset_index(drop=True)
# Remove the 'ID' column as it is likely not relevant for the model training
x_combined = x_combined.drop('ID', axis=1)
# Check for missing values across the combined dataset
missing_values = x_combined.isnull().sum()
print(missing_values)

# Drop 'Column9' from the dataset based on its limited utility for the analysis
x_combined = x_combined.drop('Column9', axis=1)
# Fill missing values in 'Column3' and 'Column4' using the mode of each column
x_combined['Column3'] = x_combined['Column3'].fillna(x_combined['Column3'].mode()[0])
x_combined['Column4'] = x_combined['Column4'].fillna(x_combined['Column4'].mode()[0])
# Replace missing values in 'Column5' with the column's mean value
x_combined['Column5'] = x_combined['Column5'].fillna(x_combined['Column5'].mean())

# Visualize the distribution of values in 'Column3' using a count plot
plt.figure(figsize=(8, 6))
sns.countplot(x='Column3', data=x_combined, color='red')
plt.title('Distribution of Column3 Values')
plt.show()

# Create a box plot for 'Column5' to visualize its distribution and identify outliers
plt.figure(figsize=(8, 6))
sns.boxplot(y='Column5', data=x_combined, color='purple')
plt.title('Box Plot of Column5')
plt.show()

# Combine training and testing data again for uniform label encoding
x_combined_encoded = pd.concat([x_train, x_test])

# Initialize a LabelEncoder to convert categorical data to numerical format
label_encoder = LabelEncoder()
x_combined_encoded = x_combined_encoded.apply(label_encoder.fit_transform)

# Split the encoded data back into training and testing datasets
x_train_encoded = x_combined_encoded.iloc[:x_train.shape[0], :]
x_test_encoded = x_combined_encoded.iloc[x_train.shape[0]:, :]

# Normalize the data using StandardScaler to ensure consistent scaling
scaler = StandardScaler()
x_train_encoded_scaled = scaler.fit_transform(x_train_encoded)
x_test_encoded_scaled = scaler.transform(x_test_encoded)

# Initialize and train a Decision Tree Classifier with a fixed random state for consistency
decision_tree_model = DecisionTreeClassifier(random_state=42)
decision_tree_model.fit(x_train_encoded_scaled, y_train['target'])
# Make predictions on the test dataset using the Decision Tree model
y_pred_dt = decision_tree_model.predict(x_test_encoded_scaled)

# Initialize and train a Logistic Regression model with a fixed random state
logistic_model = LogisticRegression(random_state=42)
logistic_model.fit(x_train_encoded_scaled, y_train['target'])
# Make predictions on the test dataset using the Logistic Regression model
y_pred_lr = logistic_model.predict(x_test_encoded_scaled)

# Evaluate and print the classification report for the Decision Tree model
print("Results for Decision Tree Classifier:")
print(classification_report(y_test['target'], y_pred_dt))

# Evaluate and print the classification report for the Logistic Regression model
print("Results for Logistic Regression:")
print(classification_report(y_test['target'], y_pred_lr))

# Save the predictions from the Decision Tree model to a CSV file
y_pred_df = pd.DataFrame(y_pred_dt, columns=['Predictions'])
y_pred_df.to_csv('final_predictions.csv', index=False)
files.download('final_predictions.csv')

# Generate the confusion matrix for the Decision Tree model's predictions
confusion_matrix_dt = confusion_matrix(y_test['target'], y_pred_dt)
# Plot the confusion matrix as a heatmap for better visualization
plt.figure(figsize=(10, 7))
sns.heatmap(confusion_matrix_dt, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix for Decision Tree Classifier')
plt.show()

